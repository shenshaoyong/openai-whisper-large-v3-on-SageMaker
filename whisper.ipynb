{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debee250",
   "metadata": {},
   "source": [
    "# OpenAI Whisper large-v3 on SageMaker\n",
    "\n",
    "***\n",
    "https://huggingface.co/openai/whisper-large-v3\n",
    "\n",
    "https://github.com/SYSTRAN/faster-whisper\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518354f",
   "metadata": {},
   "source": [
    "# setting with installing ffmpeg on notebook instance / client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41211a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****install ffmpeg on terminal *******\n",
    "\n",
    "conda install -c conda-forge ffmpeg\n",
    "ffmpeg -v\n",
    "which ffmpeg\n",
    "sudo ln -s /home/ec2-user/anaconda3/envs/JupyterSystemEnv/bin/ffmpeg /usr/bin/ffmpeg\n",
    "sudo ln -s /home/ec2-user/anaconda3/envs/JupyterSystemEnv/bin/ffprobe /usr/bin/ffprobe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b07b694",
   "metadata": {},
   "source": [
    "# installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827b4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU sagemaker boto3 openai-whisper pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f107e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/ffmpeg\r\n"
     ]
    }
   ],
   "source": [
    "# check ffmpeg is ready\n",
    "!which ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b51e0",
   "metadata": {},
   "source": [
    "# Deploying on SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec0fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe109c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'openai/whisper-large-v3',\n",
    "\t'HF_TASK':'automatic-speech-recognition'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.37.0',\n",
    "\tpytorch_version='2.1.0',\n",
    "\tpy_version='py310',\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1, # number of instances\n",
    "\tinstance_type='ml.g4dn.xlarge' # ec2 instance type\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600f6f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.mp3 's length is 54720, spilted into 3 segments~\n",
      "[0, 25000]\n",
      "{'text': \" Thank you for calling technology technical support. How can I help you? Hi, I just have a quick question on a application update that I just did. After I push the task like this, it's an A80. After I push the task, you know, it's pushing to the terminal. And if I refresh and go back in, as long as it says it's succeeded, then I know there's nothing.\"}\n",
      "[25000, 50000]\n",
      "{'text': \" else that needs to be done, correct? Yes. Okay, so there's nothing on the terminal. You know, if it went through correct at the terminal, the change should be made 100% in the terminal, correct? Yes, that's correct, sir. Okay, all right. I just want to make sure. I thought so. I just want to make sure. Okay, very good. Thank you so much. Okay, is there anything else I can update? No, no, that was it. Okay.\"}\n",
      "[50000, 54720]\n",
      "{'text': ' Okay, thank you for calling, Pat. Have a nice day. You too. Bye-bye.'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import DataSerializer\n",
    "from pydub import AudioSegment\n",
    "\n",
    "predictor.serializer = DataSerializer(content_type='audio/x-audio')\n",
    "\n",
    "AUDIO_FILE = \"2.1.mp3\"\n",
    "sound = AudioSegment.from_file(AUDIO_FILE)\n",
    "length = len(sound)\n",
    "segment_count = length // 25000 + 1\n",
    "\n",
    "print(f\"{AUDIO_FILE} 's length is {len(sound)}, spilted into {segment_count} segments~\")\n",
    "\n",
    "filename = \"temp.mp3\"\n",
    "for i in range(0,segment_count):\n",
    "    start = i*25000\n",
    "    if (i+1)==segment_count:\n",
    "        end = length\n",
    "    else:\n",
    "        end = (i+1)*25000\n",
    "    print([start,end])\n",
    "    temp = sound[start:end]\n",
    "    temp.export(filename, format=\"mp3\")\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    print(predictor.predict(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c946f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-pytorch-inference-2024-04-18-05-41-41-954\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5d0de",
   "metadata": {},
   "source": [
    "# only for re-invoke already-created endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17681010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mandarin.mp3 's length is 6984, spilted into 1 segments!\n",
      "[0, 6984]\n",
      "{'text': '如果他们使用航空的方式运输货物,在某些航线上可能要花几天的时间才能卸货和通关。'}\n"
     ]
    }
   ],
   "source": [
    "#only for re-invoke already-created endpoint\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import DataSerializer\n",
    "from pydub import AudioSegment\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "endpoint_name = endpoint_name#\"pytorch-inference-2024-04-14-16-40-53-471\"\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=serializers.DataSerializer(content_type='audio/x-audio'),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")\n",
    "\n",
    "AUDIO_FILE = \"mandarin.mp3\"#\"es-US-1.wav\"\n",
    "sound = AudioSegment.from_file(AUDIO_FILE)\n",
    "length = len(sound)\n",
    "segment_count = length // 25000 + 1\n",
    "\n",
    "print(f\"{AUDIO_FILE} 's length is {len(sound)}, spilted into {segment_count} segments!\")\n",
    "\n",
    "filename = \"temp.mp3\"\n",
    "for i in range(0,segment_count):\n",
    "    start = i*25000\n",
    "    if (i+1)==segment_count:\n",
    "        end = length\n",
    "    else:\n",
    "        end = (i+1)*25000\n",
    "    print([start,end])\n",
    "    temp = sound[start:end]\n",
    "    temp.export(filename, format=\"mp3\")\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    print(predictor.predict(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7945a60",
   "metadata": {},
   "source": [
    "# run faster_whisper in SageMaker notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4fb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faster_whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8425a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import whisper\n",
    "\n",
    "model = WhisperModel(\"large-v3\")\n",
    "# with open(\"1.mp3\", \"rb\") as f:\n",
    "#     data = f.read()\n",
    "\n",
    "audio = whisper.load_audio(\"1.mp3\")\n",
    "print(type(audio))\n",
    "segments, info = model.transcribe(audio,beam_size=5, vad_filter=True,vad_parameters=dict(min_silence_duration_ms=500))\n",
    "#segments, info = model.transcribe(\"1.m4a\",beam_size=5, vad_filter=True,vad_parameters=dict(min_silence_duration_ms=500))\n",
    "\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
